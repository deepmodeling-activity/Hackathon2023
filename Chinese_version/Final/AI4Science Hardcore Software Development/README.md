# Background of the question

AI4Science硬核软件开发赛道由DeepModeling开源社区、北京大学超算队、北京大学Linux俱乐部联合主办。本赛道鼓励选手积极参与到AI4Science本身的工具开发中。对高性能感兴趣的同学可以对指定软件进行高性能优化；对AI感兴趣的同学可以针对某些网络进行重构。又或者你发现软件中还有一些别的问题你想要改进——总之只要是和AI4Science有关的一切软件开发在这里都被鼓励！

**本赛道赛题分为自由命题和固定命题两个部分。我们特别鼓励大家做自由命题，只要和AI4Science硬核软件开发相关的任何创意都非常欢迎；当然如果大家对自由命题不知所措，也可以参与固定命题赛道，在指定的命题下发挥自己的创意与才华。**


## 赛题内容

### 一、自由命题

本赛道的选手拥有充分的创意自由，可以选择任意和AI4Science硬核软件开发相关的想法来完成。包括但不限于：

- **DeepModeling开源社区软件高性能优化**：选手可以自由浏览DeepModeling开源社区相关软件，并对自己感兴趣的部分进行高性能优化

- **DeepModeling开源社区软件开发**：选手可以自由浏览DeepModeling开源社区相关软件，并对自己感兴趣的事情进行开发。如果不确定如何下手，优先鼓励大家查看社区项目里面的相关issue，解决issue里面的问题

选择这个赛道的选手，需要在初赛阶段提交自己的proposal来描述自己的想法并初步证实该想法可行性（评审组也会给出一些建设性的指导建议，方便更好的实现）。

## 二、指定赛题

### 赛题一：高性能跨平台的邻近表算法实现

邻近表（Neighborlist）在计算化学中具有重要意义，在第一性原理计算、分子动力学模拟等领域都有重要的应用。邻近表是一种用于表示对象之间的局部关系或邻近关系的数据结构，记录了在一定截断半径范围内相邻粒子的索引，并在模拟过程中随原子的运动而动态更新。因此，无论是近程相互作用的计算，还是局域的结构性质的统计都直接依赖于邻近表。因此，临近表建立的算法优劣将显著影响计算效率。我们逐渐意识到，在不同的科学计算项目中都有共同的邻近表需求，并且可以抽象为具有明确输入与输出的算法。此外，由于科学软件的复杂性和特殊性，程序不仅仅像深度学习框架一样强烈地依赖于GPU，而且需要运行在各种架构且异构的加速平台上。我们是否可以将邻近表抽象出来并进行高度优化，形成从python、c++到cuda，从x86、arm到各种异构加速平台全覆盖的高度优化的库，从而减少重复地开发。

受计算机硬件架构特性的影响，邻近表算法在不同硬件平台上的实现和性能表现存在显著差异。因此，在设计和优化邻近表算法时，必须针对各种计算机硬件架构进行特定的实现和优化。 此外，模拟体系的性质也存在很大差异，如体系规模（从小型到大型体系）、密度分布（从稀疏到均匀密集）以及空间分布（从均匀到局部稠密）。基于这些不同的模拟体系特点，设计邻近表算法和优化策略时需要综合考虑各种因素，以确保算法在各种场景下的高效性能表现。

#### 初赛目标

在初赛中，选手们通过学习几种经典邻近表算法，自由选择编程语言实现基本算法。测试模型及标准答案请见 https://github.com/deepmodeling-activity/hackathon-test-cases

#### 决赛目标

决赛中，基于初赛成果，选手们可以自由优化，既可以在代码层面进行调优，也可以提出新型算法，乃至实现更加复杂的空间分解和负载均衡策略。最终的的评分将采用北大超算平台进行，具体使用方式将在后期推出。

#### 一些提示

为评估邻近表算法在各种情况下的正确性和性能表现，我们将提供一组覆盖常见模拟场景的测试用例（包括模型文件）以及针对不同硬件架构的测试平台。选手们可以自由选择编程语言，选择或自主设计不同的邻近表算法，要求在计算尽可能准确的基础上加快计算速度。可能需要考虑的因素有：体系规模、密度分布、空间分布、硬件架构、IO与分块等等。

#### 评分标准

评分将综合考虑算法的正确性和执行速度，并根据体系和平台的成绩进行加权计算。具体的评分权重细则将在评分标准文档中公布。

#### 决赛提交要求

我们将为参赛者提供多种不同平台的服务器，以便对其编写的代码进行测试和评估。这些平台包括基于x86和ARM架构的CPU集群，以及Nvidia和AMD的GPU设备。为了确保代码的正确性，我们将提供一套测试框架，该框架规定了代码输入与输出的格式和标准。参赛者在完成自己的代码编写后，需要将其算法接入测试框架进行相应的测试。通过这一过程，我们将能够确保参赛者的代码满足既定的性能和正确性要求，从而为比赛的公平性和可靠性提供保障。

### 赛题二：ABACUS

ABACUS是一款广泛应用于材料科学计算的高性能密度泛函理论（DFT）软件。为了充分发挥其在实际生产应用中的性能潜力，本赛题旨在挖掘并优化软件中的性能瓶颈，从而提高计算效率、节省计算资源并加速科研进程。

ABACUS支持平面波（PW）和数值原子轨道（LCAO）两种不同的基组，选手们需要在对给定的两个算例（1. LCAO基组算例，2. PW基组算例）进行性能热点分析，并自由进行性能优化。

#### 初赛目标

初赛中，选手们通过测试给定的两个算例，分析其性能热点并找到性能热点对应的代码，分析并提出初步的性能优化方案。方案可自由采用MPI优化/OpenMP并行优化或算法优化等。

#### 决赛目标

决赛中，选手们基于初赛提出的性能优化方案进行性能优化打榜比赛。指定的算例的潜在性能优化方案：1. LCAO基组算例，2. PW基组算例。

#### 算例地址：

https://github.com/deepmodeling/abacus-develop/tree/for_hackathon/hackathon_test_cases

#### 一些优化方向的提示：

**LCAO基组算例：**

1. ABACUS中的电荷密度对称化算法；

2. ABACUS中LCAO基组计算密度矩阵的MPI并行算法。

**PW基组算例：平面波基组使用迭代法求解对角化，目前ABACUS支持CG和Davidson两种对角化算法，可以：**

1. 考虑对Davidson算法进行优化(算法实现层面)或实现其他的对角化算法（LOBPCG/PPCG/RMM-DIIS等）

2. 考虑对CG或Davidson算法采用MPI/OpenMP/CUDA等高性能优化方案。

#### 评分标准

为公平评估性能优化的效果，所有选手优化后的程序将采用：1. MPI多进程并行，2. OpenMP多线程并行，3. MPI+OpenMP混合并行。三种测试方案分别对两个目标算例的热点函数耗时进行综合性能优化效果评估，评分标准方面，我们鼓励对一个热点函数进行极致的优化而不是对多个热点函数都进行适度优化，具体的评分权重细则将在评分标准文档中公布。


### 赛题三：可自动微分的点电荷长程静电作用算法

在周期性边界条件下的系统中，由于最小镜像约定的限制，邻近表方法不能有效处理长程静电相互作用。为了解决这个问题，研究人员发展了诸如Ewald、PME、PPPM等长程相互作用算法。随着系统规模的扩大，优化现有算法和开发新算法变得非常重要。在基于物理的分子力场DMFF中，我们将各种物理力场和模拟计算流视为人工智能模型的自然延伸，以第一性原理或实验数据为输入，采用先进机器学习算法反向矫正和优化物理模型参数。实现这一目标的关键是代码的自动微分功能。因此，在保证自动微分功能的前提下，如何实现高效且先进的长程静电作用算法成为一个亟待解决的问题。

#### 初赛目标

在分子动力学模拟和量子化学计算中，准确计算长程静电相互作用对于正确预测物质的性质和行为至关重要。DMFF中，我们初步实现了一种基于PME的长程静电相互作用，同时支持多极静电和色散相互作用。尽管PME方法的性能得到了很大的改进，但在大规模计算中仍然存在计算效率的瓶颈。本赛题的目标是开发新的点电荷静电相互作用算法，以优化PME方法，并在保持自动微分能力的前提下提高长程作用部分的计算速度。 有三方面的优化思路： 

1. 对现有的PME算法进行彻底的分析，以识别在JAX代码层面的优化机会。

2. JAX提供了自定义算子的功能，允许我们使用C++和CUDA实现高效的算子。这为加速计算提供了另一种途径。例如，我们可以为b-spline插值实现一个自定义算子，以提高计算效率。具体而言，我们可以将融合函数 $$F(x)$$ 实现为一个自定义算子，使其能够在GPU上快速计算。

3. 除了PME算法外，近年来研究人员还提出了许多先进的长程作用计算算法，如PMU和ScaFaCoS。研究和比较先进的静电相互作用算法，通过JAX和CUDA算子实现先进算法加速长程作用计算，以评估它们在提高计算效率方面的潜力。

选手所提出的方法需要在可自动微分的前提下加速点电荷的长程静电作用的计算。我们将评估所提出方法在DMFF框架中的性能，以证明其可以将DMFF的能力推向新的高度。我们将建立一种高效的静电相互作用计算方法，以加速分子动力学模拟和量子化学计算中长程作用部分的计算。这将为相关领域的研究人员提供更好的工具，从而加速科学发现的过程。测试模型及标准答案请见 https://github.com/deepmodeling-activity/hackathon-test-cases

#### 一些提示

初赛中，选手们学习理解PME的原理后，首先实现基本算法，并将其集成到提供的测试框架中，以评估其在各种模拟场景下的正确性和性能表现。决赛中，基于初赛成果，选手们可以自由优化，既可以在代码层面进行调优，也可以提出新型算法，从而提升各种模拟场景下的正确性和性能表现。

为评估长程作用算法在各种情况下的正确性和性能表现，我们将提供一组覆盖常见模拟场景的测试用例（包括模型文件）以及针对不同硬件架构的测试平台。选手们可以自由选择编程语言，选择或自主设计不同的邻近表算法，要求在计算尽可能准确的基础上加快计算速度。可能需要考虑的因素有：体系规模、密度分布、空间分布、硬件架构、IO与分块等等。

#### 评分标准

评分将综合考虑算法的正确性和执行速度，并根据体系和平台的成绩进行加权计算。具体的评分权重细则将在评分标准文档中公布。

#### 决赛提交要求

我们将为参赛者提供多种不同平台的服务器，以便对其编写的代码进行测试和评估。这些平台包括基于x86和ARM架构的CPU集群，以及Nvidia和AMD的GPU设备。为了确保代码的正确性，我们将提供一套测试框架，该框架规定了代码输入与输出的格式和标准。参赛者在完成自己的代码编写后，需要将其算法接入测试框架进行相应的测试。通过这一过程，我们将能够确保参赛者的代码满足既定的性能和正确性要求，从而为比赛的公平性和可靠性提供保障。评分将采用北大超算平台进行，具体使用方式将在后期推出。

### 赛题四：DeepFlame—热力学函数和输运参数的神经网络训练

在燃烧模拟中，计算更新热力学状态和输运参数是关键的一步。在工程应用中，工质入射、混合和燃烧等过程至少部分发生在跨临界或超临界状态下，可能导致燃烧模拟中常用的理想气体模型不再适用。尽管可以通过引入形式上更复杂的真实流体模型以提高燃烧模拟的准确性，但将导致模拟复杂度的增加和计算量的显著增加，定量来看，使用真实气体模型更新热力学函数和输运参数将会占用大涡模拟总计算时长的50%到75%。

#### 初赛目标

机器学习是一种潜在的计算真实流体热力学函数和输运参数的回归工具。在本赛题中，你需要训练用于计算氮气的热力学函数和输运参数的神经网络。网络的输入信息为工质的总焓和压力，输出数据为温度、密度、热扩散率、粘度和等焓压缩系数。我们提供了压力在3.5-5 MPa、温度在127-350K的数据用于训练和测试你的神经网络。

#### 一些提示

1. 数据生成

我们所提供的数据集采用基于Peng-Robinson状态方程的真实流体模型生成（自Cantera2.6版本开始提供）。如果你需要生成更多数据用于训练和测试，可自行安装Cantera并利用所提供的Python程序生成相关数据。安装方法可参考Cantera官网安装教程（https://cantera.org/install/conda-install.html#sec-install-conda），或DeepFlame安装文档（https://deepflame.deepmodeling.com/en/latest/qs/install.html）。

2. 开源框架

虽然有很多可使用的开源框架，本测试推荐使用PyTorch。

#### 评分标准

神经网络的性能评估将综合以下三方面：（1）预测准确度（越精确越好）（2）神经网络设计的精简度（参数越少越好），（3）鼓励参赛选手在完成基本要求的基础上自主扩展网络的功能，如针对多组分、宽工况等场景开展网络训练。

#### 提交要求

- 神经网络以pt或pth格式提交

- 用于神经网络推理的python脚本

- 对于神经网络的设计、性能评估的介绍文档，以word或pdf格式提交，不限制格式或字数



### 赛题五：DeepFlame—DeepFGM框架

Flamelet Generated Model（FGM）是一种使用预先计算的火焰来表示湍流反应流中火焰结构的燃烧模型。它为模拟复杂燃烧过程提供了一种高效的计算方式，并且被广泛应用在燃烧系统的CFD模拟。使用FGM模型需要基于查表计算而来的火焰面数据。然而，当又众多的反应组分，且随着变量的维度提升，用于计算的表所占用的内存将会十分巨大。DeepFGM，一种在DeepFlame里包含的湍流燃烧积分（TCI）模型，将会根据表中计算用到的每一个物理量生成量身定制的神经网络，最终减少整体的内存占用。

#### 初赛目标

此测试中，我们将提供训练数据集和它们的格式，以及一些训练用到的源代码供选手们参考。选手们需要使用提供的代码和资源来训练关于化学反应速率（$$w_c$$）的网络。在取得训练的网络之后，选手们将在DeepFlame中进行Sandia-D算例的计算。

#### 一些提示

1. 网络训练

使用的网络结构基于PyTorch框架搭建。网络的结构被定义在RES.py中。选手需要根据注释完成trian_PES.py中的代码来实现网络训练，并将网络结果以pth格式保存。

2. 案例验证


在网络训练完成之后，我们可以替换DeepFlame的Sandia-D中使用的网络来验证后期结果。对于特定的操作过程，建议参考DeepFlame训练营中关于DeePFGM的内容和相关网站。

#### 评分标准


神经网络的表现将基于两个方面：（1）表数据的预测准确度（2）后期结果

#### 提交要求

神经网络以pth格式提交

完整的train_RES.py文件


[点击这里查看更多赛题信息](https://dptechnology.feishu.cn/docx/QGfHdUHrEowMi4xYkJuchN9Rnbh?from=from_copylink)

## 作品提交方式

- 发送邮件至邮箱：hackathon@deepmodeling.com

- 邮件命名为“赛道_姓名_方向.zip”，如“AI4Science应用场景探索_小明_DMFF.zip，AI for Life Sciences_李华_自由赛道.zip”，若邮件内有附件，附件同邮件名。

- 邮件内容包含参赛者姓名，压缩包/bohrium Notebook链接（具体看赛题要求），以及必要的说明


